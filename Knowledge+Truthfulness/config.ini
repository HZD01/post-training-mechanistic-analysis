# replace weights_directory with either:
# * the *ABSOLUTE PATH* to where you store your weights, or
# * the huggingface repo with your weights


[llama-2-13b]
weights_directory = meta-llama/Llama-2-13b-hf
name = LLaMA-2-13B
probe_layer = 14
intervene_layer = 8
noperiod = False

[llama-2-13b-instruct]
weights_directory = meta-llama/Llama-2-13b-chat-hf
name = LLaMA-2-13B-instruct
probe_layer = 14
intervene_layer = 8
noperiod = False



[llama-3.1-8b]
weights_directory = meta-llama/llama-3.1-8b
name = LLaMA-3.1-8B
probe_layer = 12
intervene_layer = 8
noperiod = False


[llama-3.1-8b-instruct]
weights_directory = meta-llama/llama-3.1-8b-instruct
name = LLaMA-3.1-8B-instruct
probe_layer = 12
intervene_layer = 8
noperiod = False

[mistral-7B]

weights_directory = mistralai/Mistral-7B-v0.3
name = Mistral-7B-v0.3
probe_layer = 13
intervene_layer = 8
noperiod = False


[mistral-7B-sft]

weights_directory = nyu-dice-lab/Mistral-7B-Base-SFT-Tulu2
name = Mistral-7B-Base-SFT-Tulu2
probe_layer = 13
intervene_layer = 8
noperiod = False

; [mistral-7B-sft-2]

; weights_directory = nyu-dice-lab/Mistral-7B-Base-SFT-Tulu2-2.0
; name = Mistral-7B-Base-SFT-Tulu2-2
; probe_layer = 13
; intervene_layer = 8
; noperiod = False


[mistral-7B-instruct]

weights_directory = mistralai/Mistral-7B-Instruct-v0.3
name = Mistral-7B-Instruct-v0.3
probe_layer = 13
intervene_layer = 8
noperiod = False


[llama-tulu3-8b-sft]
weights_directory = allenai/Llama-3.1-Tulu-3-8B-SFT
name = Llama-3.1-Tulu-3-8B-SFT
probe_layer = 12
intervene_layer = 8
noperiod = False